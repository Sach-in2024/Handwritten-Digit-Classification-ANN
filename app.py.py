# -*- coding: utf-8 -*-
"""mnist-classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nyp3K5Dh5zDa_tn6yfdm2MWvbCDaQhOX
"""

import tensorflow
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense,Flatten
import numpy as np
import pandas as pd

(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()

x_train.shape

x_test.shape

y_train

y_test

import matplotlib.pyplot as plt
plt.imshow(x_train[1])

x_train = x_train/255  # For converting the value range b/t 0 or 1
x_test = x_test/255

x_train[0]

model = Sequential()
 model.add(Flatten(input_shape=(28,28)))
 model.add(Dense(128,activation='relu'))
 model.add(Dense(32,activation='relu'))
 model.add(Dense(10,activation='softmax'))

model.summary()

model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])

history = model.fit(x_train,y_train,epochs=25,validation_split=0.2)

y_prob = model.predict(x_test)

y_pred=y_prob.argmax(axis=1)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_pred)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
#plt.legend(['loss','val_loss'])

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])

plt.imshow(x_test[1])

model.predict(x_test[1].reshape(1,28,28)).argmax(axis=1)

